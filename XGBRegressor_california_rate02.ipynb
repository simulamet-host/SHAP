{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from funcs.utils import *\n",
    "from funcs.explain import *\n",
    "import shap\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from funcs.DIMV import DIMVImputation\n",
    "from funcs.miss_forest import mf\n",
    "\n",
    "missing_rate = 0.2\n",
    "nruns = 10\n",
    "ouput_name = 'XGBRegressor_california_rate02'  \n",
    "\n",
    "X, y = shap.datasets.california() \n",
    "\n",
    "def get_split():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "    X_test = pd.DataFrame(scaler.transform(X_test), columns = X_train.columns)\n",
    "\n",
    "    y_train, y_test = y_train.reshape((-1,1)), y_test.reshape((-1,1))\n",
    "    scaler_y = StandardScaler()\n",
    "    scaler_y.fit(y_train)\n",
    "    y_train = pd.DataFrame(scaler_y.transform(y_train))\n",
    "    y_test = pd.DataFrame(scaler_y.transform(y_test))    \n",
    "    X_train_star = generate_missing_data(X_train, rate=missing_rate)\n",
    "    X_test_star = generate_missing_data(X_test, rate=missing_rate) \n",
    "    return X_train, X_train_star, y_train, X_test, X_test_star, y_test\n",
    "\n",
    "chosen_model = xgboost.XGBRegressor(n_estimators=100, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate missing data, impute, and use SHAP to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(nruns):\n",
    "    X_train, X_train_star, y_train, X_test, X_test_star, y_test = get_split()\n",
    "    print('iteration:',i)\n",
    "    results.append(one_run(X_train, X_train_star, y_train, X_test, X_test_star, y_test, chosen_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_shap_vals(results, j, nruns):\n",
    "    # get the average shap values from all runs for each imputation method or the original \n",
    "    current = results[0][0][j]\n",
    "    for i in range(1, nruns):\n",
    "        current.values += results[i][0][j].values\n",
    "        current.base_values += results[i][0][j].base_values\n",
    "        current.data += results[i][0][j].data  \n",
    "    current.values = current.values/nruns\n",
    "    current.base_values = current.base_values/nruns\n",
    "    current.data = current.data/nruns\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_ori = get_average_shap_vals(results, j = 0, nruns= nruns)\n",
    "shap_values_xm = get_average_shap_vals(results, j = 1, nruns= nruns)\n",
    "shap_values_mi = get_average_shap_vals(results, j = 2, nruns = nruns)\n",
    "shap_values_mice = get_average_shap_vals(results, j = 3, nruns= nruns)\n",
    "shap_values_dimv = get_average_shap_vals(results, j = 4, nruns= nruns)\n",
    "shap_values_mf = get_average_shap_vals(results, j = 5, nruns= nruns)\n",
    "shap_values_soft = get_average_shap_vals(results, j = 6, nruns= nruns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    j = 0\n",
    "    mse_now = results[0][1][j]\n",
    "    for i in range(1, nruns):\n",
    "        mse_now += results[i][1][j]\n",
    "    mse_imputation_all = mse_now/nruns  \n",
    "    print(\"the MSE between the imputed X_test of mean imputation, MICE, DIMV, MissForest, SOFT-IMPUTE and the original X_test:\")\n",
    "    print(mse_imputation_all.round(3))\n",
    "\n",
    "    j = 1\n",
    "    mse_now = results[0][1][j]\n",
    "    for i in range(1, nruns):\n",
    "        mse_now += results[i][1][j]    \n",
    "    mse_shap_all = mse_now/nruns \n",
    "    print(\"the MSE between the Shapley values of mean imputation, MICE, DIMV, MissForest, SOFT-IMPUTE and the original:\")\n",
    "    print(mse_shap_all.round(3))\n",
    "\n",
    "    j = 2\n",
    "    mse_ypred_now = results[0][1][j]\n",
    "    for i in range(1, nruns):\n",
    "        mse_ypred_now += results[i][1][j]    \n",
    "    mse_ypred_all = mse_ypred_now/nruns \n",
    "    print(\"the MSE between y predicted on test set of mean imputation, MICE, DIMV, MissForest, SOFT-IMPUTE and the original:\")\n",
    "    print(mse_ypred_all.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot = pd.DataFrame({'MSE on y test':mse_ypred_all, 'MSE Shap': mse_shap_all}, index = dfplot.index)\n",
    "dfplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('imputation MSE versus Shapley MSE')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(dfplot['MSE on y test'],dfplot['MSE Shap'], color='skyblue')\n",
    "for i, row in dfplot.iterrows():\n",
    "    plt.text(row['MSE on y test'],row['MSE Shap'], row.name, ha='center', va='bottom')\n",
    "plt.ylabel('MSE Shap')\n",
    "plt.xlabel('MSE on y test')\n",
    "plt.xlim(0.08, 0.15)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)  # Adding grid for better visualization\n",
    "plt.savefig('results/'+ ouput_name+'imputation_mse_vs_shap_mse'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_ori, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'ori'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_xm, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'xm'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_mi, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'mi'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_mice, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'mice'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_dimv, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'dimv'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_mf, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'mf'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.beeswarm(shap_values_soft, max_display=10, show=False)\n",
    "plt.savefig('results/'+ ouput_name+'beeswarm'+'soft'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "shap.plots.bar(shap_values_ori, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_ori'+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_values_xm, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_xm'+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_values_mi, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_mi'+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_values_mice, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_mice'+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_values_dimv, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_dimv'+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_values_mf, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_mf'+'.png',bbox_inches='tight')\n",
    "\n",
    "plt.figure()\n",
    "shap.plots.bar(shap_values_soft, show=False)\n",
    "plt.savefig('results/'+ouput_name+'bar_soft'+'.png',bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
