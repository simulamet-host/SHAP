{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from funcs.utils import *\n",
    "from funcs.explainNumpy import *\n",
    "import shap\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from funcs.DIMV import DIMVImputation\n",
    "from funcs.miss_forest import mf\n",
    "\n",
    "missing_rate = 0.2\n",
    "nruns = 1\n",
    "ouput_name = 'XGBRegressor_mnist_rate02'  \n",
    "\n",
    "chosen_model = xgboost.XGBClassifier(n_estimators=100, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_index = ['Xgb on missing data','Mean Imputation','MICE','DIMV','missForest','SOFT-IMPUTE','GAIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((8,8)),  # Resizing to 8x8 to match input size of 64 (8x8)\n",
    "                                transforms.ToTensor()])\n",
    "train_dataset = datasets.MNIST(root='../../data', train=True,  transform=transform, download=False)\n",
    "test_dataset = datasets.MNIST(root='../../data', train=False, transform=transform,  download=False)\n",
    "\n",
    "X_train = np.array([train_dataset[i][0].numpy() for i in range(len(train_dataset))])\n",
    "y_train = np.array([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "\n",
    "X_test = np.array([test_dataset[i][0].numpy() for i in range(len(test_dataset))])\n",
    "y_test = np.array([test_dataset[i][1] for i in range(len(test_dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1,64))\n",
    "X_test = X_test.reshape((-1,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    # X_train = pd.DataFrame(scaler.transform(X_train), columns = X_train.columns)\n",
    "    # X_test = pd.DataFrame(scaler.transform(X_test), columns = X_train.columns)\n",
    "\n",
    "    y_train, y_test = y_train.reshape((-1,1)), y_test.reshape((-1,1)) \n",
    "    X_train_star = generate_missing_data(X_train, rate=missing_rate)\n",
    "    X_test_star = generate_missing_data(X_test, rate=missing_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate missing data, impute, and use SHAP to explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 99957/100000 [10:09<00:00]        "
     ]
    }
   ],
   "source": [
    "    ori_model = chosen_model\n",
    "    ori_model.fit(X_train, y_train)\n",
    "    explainer_ori = shap.Explainer(ori_model, X_test)\n",
    "    shap_values_ori = explainer_ori(X_test)  \n",
    "    ypred_ori = ori_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 99936/100000 [10:32<00:00]        "
     ]
    }
   ],
   "source": [
    "    xm_model = chosen_model #xgboost directly on missing data\n",
    "    xm_model.fit(X_train_star, y_train)\n",
    "    explainer_xm = shap.Explainer(xm_model, X_test_star)\n",
    "    shap_values_xm = explainer_ori(X_test_star)      \n",
    "    ypred_xm = xm_model.predict(X_test_star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 99851/100000 [09:24<00:00]        "
     ]
    }
   ],
   "source": [
    "    # impute X using mean imputation \n",
    "    X_train_mi = np.where(np.isnan(X_train_star), np.nanmean(X_train_star, axis=0), X_train_star)\n",
    "    X_test_mi = np.where(np.isnan(X_test_star), np.nanmean(X_train_star, axis=0), X_test_star)\n",
    "    model_mi = chosen_model\n",
    "    model_mi.fit(X_train_mi, y_train)\n",
    "    explainer_mi = shap.Explainer(model_mi, X_test_mi)\n",
    "    shap_values_mi = explainer_mi(X_test_mi)\n",
    "    ypred_mi = model_mi.predict(X_test_mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thung\\.conda\\envs\\mtime\\Lib\\site-packages\\sklearn\\impute\\_iterative.py:825: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "100%|===================| 99950/100000 [09:40<00:00]        "
     ]
    }
   ],
   "source": [
    "    # MICE imputation \n",
    "    imputer = IterativeImputer(max_iter=10, random_state=0)\n",
    "    imputer.fit(X_train_star)\n",
    "    X_train_mice = imputer.transform(X_train_star)\n",
    "    X_test_mice = imputer.transform(X_test_star)\n",
    "    model_mice = chosen_model\n",
    "    model_mice.fit(X_train_mice, y_train)\n",
    "    explainer_mice = shap.Explainer(model_mice, X_test_mice)\n",
    "    shap_values_mice = explainer_mice(X_test_mice)\n",
    "    ypred_mice = model_mice.predict(X_test_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Cross Validation with alphas = [0.1, 1.0, 10.0] and 10 % of training set\n",
      "Running Cross Validation, alpha=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [09:04<00:00,  8.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Validation, alpha=1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [08:21<00:00,  7.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Cross Validation, alpha=10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [08:26<00:00,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result: best alpha 0.1, best score 0.07767559240320046, scores {0.1: 0.07767559240320046, 1.0: 0.093604569562802, 10.0: 0.12687643678589122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # DIMV imputation \n",
    "    imputer = DIMVImputation()\n",
    "    X_train_star_np, X_test_star_np = np.array(X_train_star), np.array(X_test_star)\n",
    "    imputer.fit(X_train_star_np, initializing=False)\n",
    "    imputer.cross_validate(train_percent=10, alphas=[0.1, 1.0, 10.0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value alpha used in for transforming is: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 64/64 [3:23:53<00:00, 191.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value alpha used in for transforming is: 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 64/64 [04:35<00:00,  4.30s/it]\n"
     ]
    }
   ],
   "source": [
    "    X_train_dimv = imputer.transform(X_train_star_np,cross_validation=False)\n",
    "    X_test_dimv = imputer.transform(X_test_star_np,cross_validation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 99907/100000 [09:42<00:00]        "
     ]
    }
   ],
   "source": [
    "    model_dimv = chosen_model\n",
    "    model_dimv.fit(X_train_dimv, y_train)\n",
    "    explainer_dimv = shap.Explainer(model_dimv, X_test_dimv)\n",
    "    shap_values_dimv = explainer_dimv(X_test_dimv)\n",
    "    ypred_dimv = model_dimv.predict(X_test_dimv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.05559622\n",
      "loss 0.00336199\n",
      "number of runs used by missForest: 2\n",
      "loss: 0.00336199\n",
      "loss 0.055867165\n",
      "loss 0.0033109833\n",
      "number of runs used by missForest: 2\n",
      "loss: 0.0033109833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 99977/100000 [09:37<00:00]        "
     ]
    }
   ],
   "source": [
    "    # MissForest\n",
    "    # mf = MissForest().fit_transform\n",
    "    X_train_mf = mf(np.array(X_train_star))\n",
    "    X_test_mf = mf(np.vstack((X_train_star, X_test_star)))[-len(X_test_star):]\n",
    "    model_mf = chosen_model\n",
    "    model_mf.fit(X_train_mf, y_train)\n",
    "    explainer_mf = shap.Explainer(model_mf, X_test_mf)\n",
    "    shap_values_mf = explainer_mf(X_test_mf)\n",
    "    ypred_mf = model_mf.predict(X_test_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|===================| 99920/100000 [09:29<00:00]        "
     ]
    }
   ],
   "source": [
    "    # SoftImpute\n",
    "    X_train_soft = SoftImpute(verbose = False).fit_transform(X_train_star)\n",
    "    X_test_soft = SoftImpute(verbose = False).fit_transform(np.vstack((X_train_star, X_test_star)))[-len(X_test_star):]\n",
    "    model_soft = chosen_model\n",
    "    model_soft.fit(X_train_soft, y_train)\n",
    "    explainer_soft = shap.Explainer(model_soft, X_test_soft)\n",
    "    shap_values_soft = explainer_soft(X_test_soft)\n",
    "    ypred_soft = model_soft.predict(X_test_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\thung\\Downloads\\all-codes\\SHAP missing revision 1 experiments\\funcs\\GAIN\\gain.py:27: The name tf.disable_v2_behavior is deprecated. Please use tf.compat.v1.disable_v2_behavior instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\thung\\.conda\\envs\\mtime\\Lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\Users\\thung\\Downloads\\all-codes\\SHAP missing revision 1 experiments\\funcs\\GAIN\\gain.py:148: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 329.79it/s]\n",
      "100%|===================| 99952/100000 [09:27<00:00]        "
     ]
    }
   ],
   "source": [
    "    # GAIN imputation \n",
    "    from funcs.explain import impute_gain\n",
    "    # from funcs.GAIN.utils import binary_sampler, normalization, renormalization, rounding\n",
    "    imputed_gain = impute_gain(np.vstack((X_train_star, X_test_star)))\n",
    "    X_train_gain = imputed_gain[:len(X_train_star)]\n",
    "    X_test_gain = imputed_gain[len(X_train_star):]\n",
    "    model_gain = chosen_model\n",
    "    model_gain.fit(X_train_gain, y_train)\n",
    "    explainer_gain = shap.Explainer(model_gain, X_test_gain)\n",
    "    shap_values_gain = explainer_gain(X_test_gain)\n",
    "    ypred_gain = model_gain.predict(X_test_gain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    mse_imputation = lambda X_test_imputed: np.mean((np.array(X_test_imputed)-np.array(X_test))**2)\n",
    "    mse_imputation_all = np.array([mse_imputation(X_test_mi), mse_imputation(X_test_mice),\n",
    "                        mse_imputation(X_test_dimv), mse_imputation(X_test_mf),\n",
    "                        mse_imputation(X_test_soft), mse_imputation(X_test_gain)])\n",
    "\n",
    "    mse_shap = lambda computed_shap_values: np.mean((computed_shap_values - shap_values_ori.values)**2)\n",
    "    mse_shap_all = np.array([mse_shap(shap_values_xm.values),mse_shap(shap_values_mi.values), mse_shap(shap_values_mice.values),\n",
    "                        mse_shap(shap_values_dimv.values), mse_shap(shap_values_mf.values), mse_shap(shap_values_soft.values),\n",
    "                            mse_shap(shap_values_gain.values)])\n",
    "\n",
    "    mse_ypred = lambda ypred_method: np.mean((ypred_ori-ypred_method)**2)\n",
    "    mse_ypred_all = np.array([mse_ypred(ypred_xm), mse_ypred(ypred_mi), mse_ypred(ypred_mice),\n",
    "                              mse_ypred(ypred_dimv), mse_ypred(ypred_mf), mse_ypred(ypred_soft), mse_ypred(ypred_gain)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_shap_vals(results, j, nruns):\n",
    "    # get the average shap values from all runs for each imputation method or the original \n",
    "    current = results[0][0][j]\n",
    "    for i in range(1, nruns):\n",
    "        current.values += results[i][0][j].values\n",
    "        current.base_values += results[i][0][j].base_values\n",
    "        current.data += results[i][0][j].data  \n",
    "    current.values = current.values/nruns\n",
    "    current.base_values = current.base_values/nruns\n",
    "    current.data = current.data/nruns\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m shap_values_ori \u001b[38;5;241m=\u001b[39m get_average_shap_vals(results, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, nruns\u001b[38;5;241m=\u001b[39m nruns)\n\u001b[0;32m      2\u001b[0m shap_values_xm \u001b[38;5;241m=\u001b[39m get_average_shap_vals(results, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, nruns\u001b[38;5;241m=\u001b[39m nruns)\n\u001b[0;32m      3\u001b[0m shap_values_mi \u001b[38;5;241m=\u001b[39m get_average_shap_vals(results, j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, nruns \u001b[38;5;241m=\u001b[39m nruns)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "shap_values_ori = get_average_shap_vals(results, j = 0, nruns= nruns)\n",
    "shap_values_xm = get_average_shap_vals(results, j = 1, nruns= nruns)\n",
    "shap_values_mi = get_average_shap_vals(results, j = 2, nruns = nruns)\n",
    "shap_values_mice = get_average_shap_vals(results, j = 3, nruns= nruns)\n",
    "shap_values_dimv = get_average_shap_vals(results, j = 4, nruns= nruns)\n",
    "shap_values_mf = get_average_shap_vals(results, j = 5, nruns= nruns)\n",
    "shap_values_soft = get_average_shap_vals(results, j = 6, nruns= nruns)\n",
    "shap_values_gain = get_average_shap_vals(results, j = 7, nruns= nruns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot = pd.DataFrame({'MSE on y test':mse_ypred_all, 'MSE Shap': mse_shap_all}, index = cols_index)\n",
    "dfplot.round(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfplot.round(3).T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('imputation MSE versus Shapley MSE')\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(dfplot['MSE on y test'],dfplot['MSE Shap'], color='skyblue')\n",
    "for i, row in dfplot.iterrows():\n",
    "    plt.text(row['MSE on y test'],row['MSE Shap'], row.name, ha='center', va='bottom')\n",
    "plt.ylabel('MSE Shap')\n",
    "plt.xlabel('MSE on y test')\n",
    "plt.xlim(0.08, 0.15)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)  # Adding grid for better visualization\n",
    "plt.savefig('results/'+ ouput_name+'imputation_mse_vs_shap_mse'+'.png',bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Xgb on missing data</th>\n",
       "      <th>Mean Imputation</th>\n",
       "      <th>MICE</th>\n",
       "      <th>DIMV</th>\n",
       "      <th>missForest</th>\n",
       "      <th>SOFT-IMPUTE</th>\n",
       "      <th>GAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE Shap</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Xgb on missing data  Mean Imputation   MICE   DIMV  missForest  \\\n",
       "MSE                     0.000            0.004  0.001  0.001       0.000   \n",
       "MSE Shap                0.038            0.021  0.010  0.009       0.005   \n",
       "\n",
       "          SOFT-IMPUTE   GAIN  \n",
       "MSE             0.002  0.004  \n",
       "MSE Shap        0.011  0.019  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfplot = pd.DataFrame({'MSE':np.hstack((0,mse_imputation_all)), 'MSE Shap': mse_shap_all}, index = cols_index)\n",
    "dfplot.round(3).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrrr}\\n\\\\toprule\\n & Xgb on missing data & Mean Imputation & MICE & DIMV & missForest & SOFT-IMPUTE & GAIN \\\\\\\\\\n\\\\midrule\\nMSE & 0.000000 & 0.004000 & 0.001000 & 0.001000 & 0.000000 & 0.002000 & 0.004000 \\\\\\\\\\nMSE Shap & 0.038000 & 0.021000 & 0.010000 & 0.009000 & 0.005000 & 0.011000 & 0.019000 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfplot.round(3).T.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
